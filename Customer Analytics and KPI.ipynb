{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is A/B Testing?\n",
    "\n",
    "It is a tool that allows you to test two or more different ideas against each other in real world. Choose the one performing statistically better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide accurate answers, and statistically sound way to establish causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B test process\n",
    "- Define a hypothesis about product or business. \n",
    "- Randomly assign user to two different groups\n",
    "- Expose group1 to the current product rules\n",
    "- Expose group 2 to product that tests the hypothesis\n",
    "- Pick whichever performs better according to a set of KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KPI's\n",
    "- A/B tests measure impact of change on KPIs\n",
    "- examples: likelihood of side-effect, revenue, conversion rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "    Mobile App company's paid subscription and in-app purchases data\n",
    "\n",
    "Goal:\n",
    "    maintain high fee -> paid conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Load the customer_data\n",
    "customer_data = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Load the app_purchases\n",
    "app_purchases = pd.read_csv('inapp_purchases.csv')\n",
    "\n",
    "# Print the columns of customer data\n",
    "print(customer_data.head())\n",
    "\n",
    "# Print the columns of app_purchases\n",
    "print(app_purchases.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on the 'uid' and 'date' field\n",
    "uid_date_combined_data = app_purchases.merge(customer_data, on=['uid', 'date'], how='inner')\n",
    "\n",
    "# Examine the results \n",
    "print(uid_date_combined_data.head())\n",
    "print(len(uid_date_combined_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion Rate: percentage of users who subscribe after free trial\n",
    "    - stability over time\n",
    "    - importance across different users (generalizability to different demographic groups)\n",
    "    - correlation with other business metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KPI Computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean purchase price \n",
    "purchase_price_mean = purchase_data.price.agg('mean')\n",
    "\n",
    "# Examine the output \n",
    "print(purchase_price_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and median purchase price \n",
    "purchase_price_summary = purchase_data.price.agg(['mean', 'median'])\n",
    "\n",
    "# Examine the output \n",
    "print(purchase_price_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and median of price and age\n",
    "purchase_summary = purchase_data.agg({'price': ['mean', 'median'], 'age': ['mean', 'median']})\n",
    "\n",
    "# Examine the output \n",
    "print(purchase_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data \n",
    "grouped_purchase_data = purchase_data.groupby(by = ['device', 'gender'])\n",
    "\n",
    "# Aggregate the data\n",
    "purchase_summary = grouped_purchase_data.agg({'price': ['mean', 'median', 'std']})\n",
    "\n",
    "# Examine the results\n",
    "print(purchase_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Conversion Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Examine the KPI 'user conversion rate' after the free trial <br>\n",
    "\n",
    "Week One Conversion Rate: Limit to users who convert in their first week after the trial ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum lapse date? \n",
    "    lapse date: date the trial ends for a given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "current_date = pd.to_datetime('2018-03-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the maximum lapse date in our data\n",
    "print(sub_data_demo.lapse_date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove users who lapsed today or any of the prior 7 days so we allow users a full week to subscribe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion Rate = subscribers/users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users\n",
    "# latest lapse date: a week before today\n",
    "max_lapse_date = current_date - timedelta(days=7)\n",
    "# restrict to users lapsed before max_lapse_date\n",
    "conv_sub_data = sub_data_demo[(sub_data_demo.lapse_date < max_lapse_date)]\n",
    "# count the users remaining in our data\n",
    "total_users_count = conv_sub_data.price.count()\n",
    "print(total_users_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscriber\n",
    "# latest subscription date: within 7 days of lapsing\n",
    "max_sub_date = conv_sub_data.lapse_date + timedelta(days=7)\n",
    "# filte the users with non-zero subscription price who subscribed before max_sub_date\n",
    "total_subs = conv_sub_data[\n",
    "    (conv_sub_data.price > 0) &\n",
    "    (conv_sub_data.subscription_date <= max_sub_date)\n",
    "]\n",
    "# count the users remaining in our data\n",
    "total_subs_count = total_subs.price.count()\n",
    "print(total_subs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the conversion rate with our previous values\n",
    "conversion_rate = total_subs_count/total_users_count\n",
    "print(conversion_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohort Conversion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of our dataframe\n",
    "conv_sub_data = conv_sub_data.copy()\n",
    "# keep users who lapsed prior to the last 2 weeks\n",
    "max_lapse_date = current_date - timedelta(days=14)\n",
    "conv_sub_data = sub_data_demo[\n",
    "    (sub_data_demo.lapse_date <= max_lapse_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub Time = how long it took a user to subscribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the days between lapse and subscrition if they subscribed and pd.NaT otherwise\n",
    "sub_time = np.where( # ifelse function of R equivalent\n",
    "    # if: a subscription date exists\n",
    "        conv_sub_data.subscription_date.notnull(),\n",
    "    # then: find how many days since their lapse\n",
    "        (conv_sub_data.subscription_date - conv_sub_data.lapse_date).dt.days,\n",
    "    # else: set the value to pd.NaT\n",
    "        pd.NaT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column 'sub_time'\n",
    "conv_sub_data['sub_time'] = sub_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcr7() and gcr14() functions\n",
    "# group by the relevant cohorts\n",
    "purchase_cohorts = conv_sub_data.groupby(by=['gender','device'], as_index=False)\n",
    "# find the conversion rate for each cohort using gcr7, gcr14\n",
    "purchase_cohorts.agg({'sub_time': ['gcr7', 'gcr14']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about how long does it take to determine a KPI\n",
    "1. monthly KPI takes too long\n",
    "\n",
    "Relevance to Business goals?\n",
    "\n",
    "Conversion Rate\n",
    "- strong measure of growth\n",
    "- see how changes impact different groups differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Purchase \n",
    "\n",
    "This KPI can provide a sense of the popularity of different in-app purchase price points to users within their first month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max_purchase_date \n",
    "max_purchase_date = current_date - timedelta(days=28)\n",
    "# Filter to only include users who registered before our max date\n",
    "purchase_data_filt = purchase_data[purchase_data.reg_date < max_purchase_date]\n",
    "# Filter this dataset to only include purchases that occurred on a date within the first 28 days.\n",
    "# Filter to contain only purchases within the first 28 days of registration\n",
    "purchase_data_filt = purchase_data_filt[(purchase_data_filt.date <= \n",
    "                        purchase_data_filt.reg_date + timedelta(days=28))]\n",
    "# Output the mean price paid per purchase\n",
    "print(purchase_data_filt.price.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same KPI, average purchase price, and a similar one, median purchase price, within the first 28 days.\n",
    "We can calculate these metrics across a set of cohorts and see what differences emerge. This is a useful task as it can help us understand how behaviors vary across cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the max registration date to be one month before today\n",
    "max_reg_date = current_date - timedelta(days=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use np.where to create an array month1 containing:\n",
    "\n",
    "the price of the purchase purchase, if \n",
    "1. the user registration .reg_date occurred at most 28 days ago (i.e. before max_reg_date), and\n",
    "2. the date of purchase .date occurred within 28 days of registration date .reg_date;\n",
    "3. NaN, otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the month 1 values\n",
    "month1 = np.where((purchase_data.reg_date < max_reg_date) &\n",
    "                 (purchase_data.date < purchase_data.reg_date + timedelta(days=28)),\n",
    "                  purchase_data.price, \n",
    "                  np.NaN)\n",
    "# Update the value in the DataFrame \n",
    "purchase_data['month1'] = month1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the month1 and price data \n",
    "purchase_summary = purchase_data_upd.agg(\n",
    "                        {'month1': ['mean', 'median'],\n",
    "                        'price': ['mean', 'median']})\n",
    "\n",
    "# Examine the results \n",
    "print(purchase_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturday January 27, 2017\n",
    "# Provide the correct format for the date\n",
    "date_data_one = pd.to_datetime(date_data_one, format='%A %B %d, %Y')\n",
    "print(date_data_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017-08-01\n",
    "date_data_two = pd.to_datetime(date_data_two, format='%Y-%m-%d')\n",
    "print(date_data_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08/17/1978\n",
    "date_data_three = pd.to_datetime(date_data_three, format=''%m/%d/%Y')\n",
    "print(date_data_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016 March 01 01:56\n",
    "date_data_four = pd.to_datetime(date_data_four, format='%Y %B %d %H:%M')\n",
    "print(date_data_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time series data\n",
    "In trying to boost purchases, we have made some changes to our introductory in-app purchase pricing. In this exercise, we check if this is having an impact on the number of purchases made by purchasing users during their first week.\n",
    "\n",
    "The dataset user_purchases has been joined to the demographics data and properly filtered. The column 'first_week_purchases' that is 1 for a first week purchase and 0 otherwise has been added. This column is converted to the average number of purchases made per day by users in their first week.\n",
    "\n",
    "We will try to view the impact of this change by looking at a graph of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data and aggregate first_week_purchases\n",
    "user_purchases = user_purchases.groupby(by=['reg_date', 'uid']).agg({'first_week_purchases': ['sum']})\n",
    "\n",
    "# Reset the indexes\n",
    "user_purchases.columns = user_purchases.columns.droplevel(level=1)\n",
    "user_purchases.reset_index(inplace=True)\n",
    "\n",
    "# Find the average number of purchases per day by first-week users\n",
    "user_purchases = user_purchases.groupby(by=['reg_date']).agg({'first_week_purchases': ['mean']})\n",
    "user_purchases.columns = user_purchases.columns.droplevel(level=1)\n",
    "user_purchases.reset_index(inplace=True)\n",
    "\n",
    "# Plot the results\n",
    "user_purchases.plot(x='reg_date', y='first_week_purchases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting our data\n",
    "there does seem to be an increase in the number of purchases by purchasing users within their first week. Let's now confirm that this is not driven only by one segment of users. We'll do this by first pivoting our data by 'country' and then by 'device'. Our change is designed to impact all of these groups equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the user_purchases_country table such that we have our first_week_purchases as our values, the country as the column, and our reg_date as the row.\n",
    "country_pivot = pd.pivot_table(user_purchases_country, values=['first_week_purchases'], columns=['country'], index=['reg_date'])\n",
    "print(country_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the user_purchases_device table such that we have our first_week_purchases as our values, the device as the column, and our reg_date as the row.\n",
    "device_pivot = pd.pivot_table(user_purchases_device, values=['first_week_purchases'], columns=['device'], index=['reg_date'])\n",
    "print(device_pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot by 'country' and then by 'device' and examine the results. See the observed lift across all groups as designed. This would point to the change being the cause of the lift, not some other event impacting the purchase rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average first week purchases for each country by registration date\n",
    "country_pivot.plot(x='reg_date', y=['USA', 'CAN', 'FRA', 'BRA', 'TUR', 'DEU'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average first week purchases for each device by registration date\n",
    "device_pivot.plot(x='reg_date', y=['and', 'iOS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Noise: Seasonality and moving averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at the overall revenue data for our meditation app. We saw strong purchase growth in one of our products, and now we want to see if that is leading to a corresponding rise in revenue. revenue is very seasonal, so we want to correct for that and unlock macro trends.\n",
    "\n",
    "we will correct for weekly, monthly, and yearly seasonality and plot these over our raw data. This can reveal trends in a very powerful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 7_day_rev\n",
    "daily_revenue['7_day_rev'] = daily_revenue.revenue.rolling(window=7,center=False).mean()\n",
    "\n",
    "# Compute 28_day_rev\n",
    "daily_revenue['28_day_rev'] = daily_revenue.revenue.rolling(window=28,center=False).mean()\n",
    "    \n",
    "# Compute 365_day_rev\n",
    "daily_revenue['365_day_rev'] = daily_revenue.revenue.rolling(window=365,center=False).mean()\n",
    "    \n",
    "# Plot date, and revenue, along with the 3 rolling functions (in order)    \n",
    "daily_revenue.plot(x='date', y=['revenue', '7_day_rev', '28_day_rev', '365_day_rev', ])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we saw that our revenue is somewhat flat over time. we will dive deeper into the data to see if we can determine why this is the case. We will look at the revenue for a single in-app purchase product we are selling to see if this potentially reveals any trends. As this will have less data then looking at our overall revenue it will be much noisier. To account for this we will smooth the data using an exponential rolling average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 'small_scale'\n",
    "daily_revenue['small_scale'] = daily_revenue.revenue.ewm(span=10).mean()\n",
    "\n",
    "# Calculate 'medium_scale'\n",
    "daily_revenue['medium_scale'] = daily_revenue.revenue.ewm(span=100).mean()\n",
    "\n",
    "# Calculate 'large_scale'\n",
    "daily_revenue['large_scale'] = daily_revenue.revenue.ewm(span=500).mean()\n",
    "\n",
    "# Plot 'date' on the x-axis and, our three averages and 'revenue'\n",
    "# on the y-axis\n",
    "daily_revenue.plot(x = 'date', y =['revenue', 'small_scale', 'medium_scale', 'large_scale'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Everything Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing user spending\n",
    "Recently, the Product team made some big changes to both the Android & iOS apps. They do not have any direct concerns about the impact of these changes, but want you to monitor the data to make sure that the changes don't hurt company revenue. Additionally, the product team believes that some of these changes may impact female users more than male users.\n",
    "\n",
    "Plot the monthly revenue for one of the updated products and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot user_revenue\n",
    "pivoted_data = pd.pivot_table(user_revenue, values ='revenues', columns=['device', 'gender'], index='month')\n",
    "\n",
    "# Remove the first and last row of the DataFrame once pivoted to prevent discontinuities from distorting the results.\n",
    "pivoted_data = pivoted_data[1:(len(pivoted_data) -1 )]\n",
    "\n",
    "# Create and show the plot\n",
    "pivoted_data.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
